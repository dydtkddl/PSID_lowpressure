{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b011b95f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "940a2b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] 넓은 형태 저장(Chunk 통합): mof_times_wide.csv\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\PSID_PC_20\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\categorical.py:460\u001b[0m, in \u001b[0;36mCategorical.__init__\u001b[1;34m(self, values, categories, ordered, dtype, fastpath, copy)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 460\u001b[0m     codes, categories \u001b[38;5;241m=\u001b[39m \u001b[43mfactorize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\PSID_PC_20\\anaconda3\\Lib\\site-packages\\pandas\\core\\algorithms.py:795\u001b[0m, in \u001b[0;36mfactorize\u001b[1;34m(values, sort, use_na_sentinel, size_hint)\u001b[0m\n\u001b[0;32m    793\u001b[0m             values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(null_mask, na_value, values)\n\u001b[1;32m--> 795\u001b[0m     codes, uniques \u001b[38;5;241m=\u001b[39m \u001b[43mfactorize_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_na_sentinel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_na_sentinel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m        \u001b[49m\u001b[43msize_hint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize_hint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    801\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sort \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\PSID_PC_20\\anaconda3\\Lib\\site-packages\\pandas\\core\\algorithms.py:595\u001b[0m, in \u001b[0;36mfactorize_array\u001b[1;34m(values, use_na_sentinel, size_hint, na_value, mask)\u001b[0m\n\u001b[0;32m    594\u001b[0m table \u001b[38;5;241m=\u001b[39m hash_klass(size_hint \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(values))\n\u001b[1;32m--> 595\u001b[0m uniques, codes \u001b[38;5;241m=\u001b[39m \u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfactorize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    596\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    597\u001b[0m \u001b[43m    \u001b[49m\u001b[43mna_sentinel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    598\u001b[0m \u001b[43m    \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    599\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    600\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_na\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_na_sentinel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    601\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    603\u001b[0m \u001b[38;5;66;03m# re-cast e.g. i8->dt64/td64, uint8->bool\u001b[39;00m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7281\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.factorize\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7195\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable._unique\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'list'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 103\u001b[0m\n\u001b[0;32m    101\u001b[0m         long_rows\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMOF\u001b[39m\u001b[38;5;124m\"\u001b[39m: mof, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfolder\u001b[39m\u001b[38;5;124m\"\u001b[39m: bf, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m\"\u001b[39m: t})\n\u001b[0;32m    102\u001b[0m long_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(long_rows)\n\u001b[1;32m--> 103\u001b[0m long_df \u001b[38;5;241m=\u001b[39m \u001b[43mlong_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMOF\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfolder\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_natural_key\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m long_df\u001b[38;5;241m.\u001b[39mto_csv(SAVE_LONG, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8-sig\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[OK] 길게(tidy) 형태 저장(Chunk 통합): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSAVE_LONG\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\PSID_PC_20\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:7183\u001b[0m, in \u001b[0;36mDataFrame.sort_values\u001b[1;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[0;32m   7175\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   7176\u001b[0m         \u001b[38;5;66;03m# error: List comprehension has incompatible type List[Series];\u001b[39;00m\n\u001b[0;32m   7177\u001b[0m         \u001b[38;5;66;03m# expected List[ndarray]\u001b[39;00m\n\u001b[0;32m   7178\u001b[0m         keys \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   7179\u001b[0m             Series(k, name\u001b[38;5;241m=\u001b[39mname)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   7180\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m (k, name) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(keys, by)\n\u001b[0;32m   7181\u001b[0m         ]\n\u001b[1;32m-> 7183\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[43mlexsort_indexer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   7184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mascending\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_position\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey\u001b[49m\n\u001b[0;32m   7185\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   7186\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(by):\n\u001b[0;32m   7187\u001b[0m     \u001b[38;5;66;03m# len(by) == 1\u001b[39;00m\n\u001b[0;32m   7189\u001b[0m     k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_label_or_level_values(by[\u001b[38;5;241m0\u001b[39m], axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[1;32mc:\\Users\\PSID_PC_20\\anaconda3\\Lib\\site-packages\\pandas\\core\\sorting.py:351\u001b[0m, in \u001b[0;36mlexsort_indexer\u001b[1;34m(keys, orders, na_position, key, codes_given)\u001b[0m\n\u001b[0;32m    349\u001b[0m     n \u001b[38;5;241m=\u001b[39m codes\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(codes) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    350\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 351\u001b[0m     cat \u001b[38;5;241m=\u001b[39m \u001b[43mCategorical\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mordered\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    352\u001b[0m     codes \u001b[38;5;241m=\u001b[39m cat\u001b[38;5;241m.\u001b[39mcodes\n\u001b[0;32m    353\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(cat\u001b[38;5;241m.\u001b[39mcategories)\n",
      "File \u001b[1;32mc:\\Users\\PSID_PC_20\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\categorical.py:462\u001b[0m, in \u001b[0;36mCategorical.__init__\u001b[1;34m(self, values, categories, ordered, dtype, fastpath, copy)\u001b[0m\n\u001b[0;32m    460\u001b[0m     codes, categories \u001b[38;5;241m=\u001b[39m factorize(values, sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 462\u001b[0m     codes, categories \u001b[38;5;241m=\u001b[39m \u001b[43mfactorize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    463\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype\u001b[38;5;241m.\u001b[39mordered:\n\u001b[0;32m    464\u001b[0m         \u001b[38;5;66;03m# raise, as we don't have a sortable data structure and so\u001b[39;00m\n\u001b[0;32m    465\u001b[0m         \u001b[38;5;66;03m# the user should give us one by specifying categories\u001b[39;00m\n\u001b[0;32m    466\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    467\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not ordered, please \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    468\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexplicitly specify the categories order \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    469\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mby passing in a categories argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    470\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\PSID_PC_20\\anaconda3\\Lib\\site-packages\\pandas\\core\\algorithms.py:795\u001b[0m, in \u001b[0;36mfactorize\u001b[1;34m(values, sort, use_na_sentinel, size_hint)\u001b[0m\n\u001b[0;32m    792\u001b[0m             \u001b[38;5;66;03m# Don't modify (potentially user-provided) array\u001b[39;00m\n\u001b[0;32m    793\u001b[0m             values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(null_mask, na_value, values)\n\u001b[1;32m--> 795\u001b[0m     codes, uniques \u001b[38;5;241m=\u001b[39m \u001b[43mfactorize_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_na_sentinel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_na_sentinel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m        \u001b[49m\u001b[43msize_hint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize_hint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    801\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sort \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    802\u001b[0m     uniques, codes \u001b[38;5;241m=\u001b[39m safe_sort(\n\u001b[0;32m    803\u001b[0m         uniques,\n\u001b[0;32m    804\u001b[0m         codes,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    807\u001b[0m         verify\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    808\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\PSID_PC_20\\anaconda3\\Lib\\site-packages\\pandas\\core\\algorithms.py:595\u001b[0m, in \u001b[0;36mfactorize_array\u001b[1;34m(values, use_na_sentinel, size_hint, na_value, mask)\u001b[0m\n\u001b[0;32m    592\u001b[0m hash_klass, values \u001b[38;5;241m=\u001b[39m _get_hashtable_algo(values)\n\u001b[0;32m    594\u001b[0m table \u001b[38;5;241m=\u001b[39m hash_klass(size_hint \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(values))\n\u001b[1;32m--> 595\u001b[0m uniques, codes \u001b[38;5;241m=\u001b[39m \u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfactorize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    596\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    597\u001b[0m \u001b[43m    \u001b[49m\u001b[43mna_sentinel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    598\u001b[0m \u001b[43m    \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    599\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    600\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_na\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_na_sentinel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    601\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    603\u001b[0m \u001b[38;5;66;03m# re-cast e.g. i8->dt64/td64, uint8->bool\u001b[39;00m\n\u001b[0;32m    604\u001b[0m uniques \u001b[38;5;241m=\u001b[39m _reconstruct_data(uniques, original\u001b[38;5;241m.\u001b[39mdtype, original)\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7281\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.factorize\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7195\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable._unique\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# ── 설정 ─────────────────────────────────────────────────────────\n",
    "ROOT = Path(\".\")                 # 탐색 시작 경로\n",
    "LOG_NAME = \"99_progress.log\"     # 로그 파일 이름\n",
    "SAVE_WIDE = \"mof_times_wide.csv\" # 넓은 형태 출력 (chunk 통합 열)\n",
    "SAVE_LONG = \"mof_times_long.csv\" # 길게(tidy) 형태 출력 (chunk 통합)\n",
    "SAVE_CONFLICTS = \"mof_time_conflicts.csv\"  # 중복 MOF 타임 충돌 기록\n",
    "\n",
    "# ── 유틸: 자연스러운 정렬(숫자 포함 폴더명 정렬용) ────────────────\n",
    "def _natural_key(s: str):\n",
    "    return [int(tok) if tok.isdigit() else tok for tok in re.split(r'(\\d+)', s)]\n",
    "\n",
    "# ── chunk 제거한 아이덴티티 ───────────────────────────────────────\n",
    "#  ex) \"Ar_313_15_chunk_2\" -> \"Ar_313_15\"\n",
    "CHUNK_RE = re.compile(r\"(.*?)(_chunk_\\d+)$\")\n",
    "def base_identity(folder_name: str) -> str:\n",
    "    m = CHUNK_RE.match(folder_name)\n",
    "    return m.group(1) if m else folder_name\n",
    "\n",
    "# ── 라인 파서: 한 줄에서 (mof, time) 뽑기 ─────────────────────────\n",
    "def parse_line(line: str):\n",
    "    if \"TimeForThis=\" not in line:\n",
    "        return None, None\n",
    "    m_time = re.search(r\"TimeForThis=(\\d+)\", line)\n",
    "    if not m_time:\n",
    "        return None, None\n",
    "    time_val = int(m_time.group(1))\n",
    "\n",
    "    part = line\n",
    "    if \"] \" in line:\n",
    "        part = line.split(\"] \", 1)[1]\n",
    "    if \" Done.\" in part:\n",
    "        part = part.split(\" Done.\", 1)[0]\n",
    "    part = part.strip()\n",
    "\n",
    "    toks = part.split(\"_\")\n",
    "    if len(toks) >= 5:\n",
    "        mof = \"_\".join(toks[:-4])\n",
    "    else:\n",
    "        mof = part\n",
    "\n",
    "    mof = mof.strip()\n",
    "    if not mof:\n",
    "        return None, None\n",
    "    return mof, time_val\n",
    "\n",
    "# ── 모든 폴더의 로그 수집 ─────────────────────────────────────────\n",
    "log_files = list(ROOT.rglob(f\"{LOG_NAME}\"))\n",
    "\n",
    "# data[mof][base_folder] = time  (chunk 통합)\n",
    "data = defaultdict(dict)\n",
    "conflicts = []  # 같은 (MOF, base_folder)에 상이한 time이 여러 번 기록된 경우\n",
    "\n",
    "for log_path in log_files:\n",
    "    folder_name = log_path.parent.name\n",
    "    base_folder = base_identity(folder_name)\n",
    "    try:\n",
    "        with open(log_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "            for line in f:\n",
    "                mof, time_val = parse_line(line)\n",
    "                if mof is None:\n",
    "                    continue\n",
    "                # 이미 값이 있는데 다른 값이면 충돌 기록(마지막 값으로 덮어씀)\n",
    "                old = data[mof].get(base_folder, None)\n",
    "                if old is not None and old != time_val:\n",
    "                    conflicts.append({\n",
    "                        \"MOF\": mof,\n",
    "                        \"base_folder\": base_folder,\n",
    "                        \"prev_time\": old,\n",
    "                        \"new_time\": time_val,\n",
    "                        \"chunk_file\": str(log_path)\n",
    "                    })\n",
    "                data[mof][base_folder] = time_val\n",
    "    except FileNotFoundError:\n",
    "        continue\n",
    "\n",
    "# ── DataFrame 구성 (wide) ─────────────────────────────────────────\n",
    "if not data:\n",
    "    print(\"수집된 데이터가 없습니다. 로그 형식/경로를 확인하세요.\")\n",
    "else:\n",
    "    all_folders = sorted({bf for inner in data.values() for bf in inner.keys()}, key=_natural_key)\n",
    "    all_mofs = sorted(list(data.keys()), key=_natural_key)\n",
    "\n",
    "    wide_df = pd.DataFrame(index=all_mofs, columns=all_folders, dtype=\"Int64\")\n",
    "    for mof in all_mofs:\n",
    "        for bf in all_folders:\n",
    "            wide_df.at[mof, bf] = data[mof].get(bf, None)\n",
    "\n",
    "    wide_df.to_csv(SAVE_WIDE, encoding=\"utf-8-sig\")\n",
    "    print(f\"[OK] 넓은 형태 저장(Chunk 통합): {SAVE_WIDE}\")\n",
    "\n",
    "    # Long/Tidy 형태\n",
    "    long_rows = []\n",
    "    for mof, rowdict in data.items():\n",
    "        for bf, t in rowdict.items():\n",
    "            long_rows.append({\"MOF\": mof, \"folder\": bf, \"time\": t})\n",
    "    long_df = pd.DataFrame(long_rows)\n",
    "    long_df = long_df.sort_values([\"MOF\", \"folder\"], key=lambda s: s.map(str).map(_natural_key))\n",
    "    long_df.to_csv(SAVE_LONG, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"[OK] 길게(tidy) 형태 저장(Chunk 통합): {SAVE_LONG}\")\n",
    "\n",
    "    # 충돌 기록(있을 때만)\n",
    "    if conflicts:\n",
    "        conf_df = pd.DataFrame(conflicts)\n",
    "        conf_df.to_csv(SAVE_CONFLICTS, index=False, encoding=\"utf-8-sig\")\n",
    "        print(f\"[INFO] 동일 (MOF, folder)에서 서로 다른 time 발견 → {SAVE_CONFLICTS}에 기록.\")\n",
    "    else:\n",
    "        print(\"[INFO] 충돌 없음 (같은 MOF가 동일 아이덴티티에서 복수 chunk에 상이한 time을 갖지 않음).\")\n",
    "\n",
    "    print(\"\\n[미리보기: wide head(10)]\")\n",
    "    print(wide_df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6a1fe7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        content = file.read()\n",
    "    return content\n",
    "\n",
    "txt = open_file('./99_progress.log')\n",
    "lines = txt.splitlines()\n",
    "lines = lines[1:-1]\n",
    "def time_crop(str):\n",
    "    if \"TimeForThis\" in str:\n",
    "        time = re.findall(r'TimeForThis=(\\d+)', str)[0]\n",
    "        mof = '_'.join(str.split(\"] \")[1].split(\" Done.\")[0].split(\"_\")[:-4])\n",
    "        return time, mof \n",
    "    return None, None \n",
    "\n",
    "lis = []\n",
    "for line in lines:\n",
    "    \n",
    "    lis.append(time_crop(line))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ffc2963b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mof</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DURDIF_clean</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DANZEZ_charged</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GIQXIO_clean</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZESFUY_clean</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GIFKIP_clean</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8260</th>\n",
       "      <td>QOWRAV10_clean</td>\n",
       "      <td>965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8261</th>\n",
       "      <td>VIWMOF_clean</td>\n",
       "      <td>1092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8262</th>\n",
       "      <td>TIRQOB_clean</td>\n",
       "      <td>892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8263</th>\n",
       "      <td>KAVJEX_clean</td>\n",
       "      <td>1260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8264</th>\n",
       "      <td>VAHTUW_clean</td>\n",
       "      <td>2194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8265 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 mof  time\n",
       "0       DURDIF_clean   103\n",
       "1     DANZEZ_charged   122\n",
       "2       GIQXIO_clean   125\n",
       "3       ZESFUY_clean   128\n",
       "4       GIFKIP_clean   142\n",
       "...              ...   ...\n",
       "8260  QOWRAV10_clean   965\n",
       "8261    VIWMOF_clean  1092\n",
       "8262    TIRQOB_clean   892\n",
       "8263    KAVJEX_clean  1260\n",
       "8264    VAHTUW_clean  2194\n",
       "\n",
       "[8265 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lis2 = []\n",
    "for i in [ x for x in lis if x[0] is not None]:\n",
    "    time = i[0]\n",
    "    mof = i[1]\n",
    "    dic = {'mof': mof, 'time': time}\n",
    "    lis2.append(dic)\n",
    "df = pandas.DataFrame(lis2)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
